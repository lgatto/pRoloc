<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Machine learning techniques available in pRoloc • pRoloc</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Machine learning techniques available in pRoloc">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">pRoloc</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.45.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/v01-pRoloc-tutorial.html">Using pRoloc for spatial proteomics data analysis</a></li>
    <li><a class="dropdown-item" href="../articles/v02-pRoloc-ml.html">Machine learning techniques available in pRoloc</a></li>
    <li><a class="dropdown-item" href="../articles/v03-pRoloc-bayesian.html">Bayesian Analysis of Spatial Proteomics data using pRoloc</a></li>
    <li><a class="dropdown-item" href="../articles/v04-pRoloc-goannotations.html">Annotating spatial proteomics data</a></li>
    <li><a class="dropdown-item" href="../articles/v05-pRoloc-transfer-learning.html">A transfer learning algorithm for spatial proteomics</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/lgatto/pRoloc/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Machine learning techniques available in pRoloc</h1>
                        <h4 data-toc-skip class="author">Laurent
Gatto</h4>
            <address class="author_afil">
      de Duve Institute, UCLouvain, Belgium<br><small class="dont-index">Source: <a href="https://github.com/lgatto/pRoloc/blob/master/vignettes/v02-pRoloc-ml.Rmd" class="external-link"><code>vignettes/v02-pRoloc-ml.Rmd</code></a></small>
      <div class="d-none name"><code>v02-pRoloc-ml.Rmd</code></div>
    </address>
</div>

    
        <div class="abstract">
      <p class="abstract">Abstract</p>
      <p>This vignette provides a general background about machine
      learning (ML) methods and concepts, and their application to the
      analysis of spatial proteomics data in the <em>pRoloc</em>
      package. See the <code>pRoloc-tutorial</code> vignette for details
      about the package itself.</p>
    </div>
    
<script type="text/javascript">
document.addEventListener("DOMContentLoaded", function() {
  document.querySelector("h1").className = "title";
});
</script><script type="text/javascript">
document.addEventListener("DOMContentLoaded", function() {
  var links = document.links;  
  for (var i = 0, linksLength = links.length; i < linksLength; i++)
    if (links[i].hostname != window.location.hostname)
      links[i].target = '_blank';
});
</script><div class="section level2">
<h2 id="sec:intro">Introduction<a class="anchor" aria-label="anchor" href="#sec:intro"></a>
</h2>
<p>For a general practical introduction to <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>,
readers are referred to the tutorial, available using
<code>vignette("pRoloc-tutorial", package = "pRoloc")</code>. The
following document provides a overview of the algorithms available in
the package. The respective section describe unsupervised machine
learning (USML), supervised machine learning (SML), semi-supervised
machine learning (SSML) as implemented in the novelty detection
algorithm and transfer learning.</p>
</div>
<div class="section level2">
<h2 id="data-sets">Data sets<a class="anchor" aria-label="anchor" href="#data-sets"></a>
</h2>
<p>We provide 144 test data sets in the <em><a href="https://bioconductor.org/packages/3.21/pRolocdata" class="external-link">pRolocdata</a></em>
package that can be readily used with <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>.
The data set can be listed with <em>pRolocdata</em> and loaded with the
<em>data</em> function. Each data set, including its origin, is
individually documented.</p>
<p>The data sets are distributed as <em>MSnSet</em> instances. Briefly,
these are dedicated containers for quantitation data as well as feature
and sample meta-data. More details about <em>MSnSet</em>s are available
in the <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>
tutorial and in the <em><a href="https://bioconductor.org/packages/3.21/MSnbase" class="external-link">MSnbase</a></em>
package, that defined the class.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/lgatto/pRolocdata" class="external-link">"pRolocdata"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">tan2009r1</span><span class="op">)</span></span>
<span><span class="va">tan2009r1</span></span></code></pre></div>
<pre><code><span><span class="co">## MSnSet (storageMode: lockedEnvironment)</span></span>
<span><span class="co">## assayData: 888 features, 4 samples </span></span>
<span><span class="co">##   element names: exprs </span></span>
<span><span class="co">## protocolData: none</span></span>
<span><span class="co">## phenoData</span></span>
<span><span class="co">##   sampleNames: X114 X115 X116 X117</span></span>
<span><span class="co">##   varLabels: Fractions</span></span>
<span><span class="co">##   varMetadata: labelDescription</span></span>
<span><span class="co">## featureData</span></span>
<span><span class="co">##   featureNames: P20353 P53501 ... P07909 (888 total)</span></span>
<span><span class="co">##   fvarLabels: FBgn Protein.ID ... markers.tl (16 total)</span></span>
<span><span class="co">##   fvarMetadata: labelDescription</span></span>
<span><span class="co">## experimentData: use 'experimentData(object)'</span></span>
<span><span class="co">##   pubMedIds: 19317464 </span></span>
<span><span class="co">## Annotation:  </span></span>
<span><span class="co">## - - - Processing information - - -</span></span>
<span><span class="co">## Added markers from  'mrk' marker vector. Thu Jul 16 22:53:44 2015 </span></span>
<span><span class="co">##  MSnbase version: 1.17.12</span></span></code></pre>
<div class="section level3">
<h3 class="unnumbered" id="other-omics-data">Other omics data<a class="anchor" aria-label="anchor" href="#other-omics-data"></a>
</h3>
<p>While our primary biological domain is quantitative proteomics, with
special emphasis on spatial proteomics, the underlying class
infrastructure on which <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em> and
implemented in the Bioconductor <em><a href="https://bioconductor.org/packages/3.21/MSnbase" class="external-link">MSnbase</a></em>
package enables the conversion from/to transcriptomics data, in
particular microarray data available as <em>ExpressionSet</em> objects
using the <em>as</em> coercion methods (see the <em>MSnSet</em> section
in the <code>MSnbase-development</code> vignette). As a result, it is
straightforward to apply the methods summarised here in detailed in the
other <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>
vignettes to these other data structures.</p>
</div>
</div>
<div class="section level2">
<h2 id="sec:usml">Unsupervised machine learning<a class="anchor" aria-label="anchor" href="#sec:usml"></a>
</h2>
<p>Unsupervised machine learning refers to clustering, i.e. finding
structure in a quantitative, generally multi-dimensional data set of
unlabelled data.</p>
<p>Currently, unsupervised clustering facilities are available through
the <em>plot2D</em> function and the <em><a href="https://bioconductor.org/packages/3.21/MLInterfaces" class="external-link">MLInterfaces</a></em>
package <span class="citation">(Carey et al., n.d.)</span>. The former
takes an <em>MSnSet</em> instance and represents the data on a scatter
plot along the first two principal components. Arbitrary feature
meta-data can be represented using different colours and point
characters. The reader is referred to the manual page available through
<em>?plot2D</em> for more details and examples.</p>
<p><em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>
also implements a <em>MLean</em> method for <em>MSnSet</em> instances,
allowing to use the relevant infrastructure with the organelle
proteomics framework. Although provides a common interface to
unsupervised and numerous supervised algorithms, we refer to the <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>
tutorial for its usage to several clustering algorithms.</p>
<p><strong>Note</strong> Current development efforts in terms of
clustering are described on the <em>Clustering infrastructure</em> wiki
page (<a href="https://github.com/lgatto/pRoloc/wiki/Clustering-infrastructure" class="external-link uri">https://github.com/lgatto/pRoloc/wiki/Clustering-infrastructure</a>)
and will be incorporated in future version of the package.</p>
</div>
<div class="section level2">
<h2 id="sec:sml">Supervised machine learning<a class="anchor" aria-label="anchor" href="#sec:sml"></a>
</h2>
<p>Supervised machine learning refers to a broad family of
classification algorithms. The algorithms learns from a modest set of
labelled data points called the training data. Each training data
example consists of a pair of inputs: the actual data, generally
represented as a vector of numbers and a class label, representing the
membership to exactly 1 of multiple possible classes. When there are
only two possible classes, on refers to binary classification. The
training data is used to construct a model that can be used to
classifier new, unlabelled examples. The model takes the numeric vectors
of the unlabelled data points and return, for each of these inputs, the
corresponding mapped class.</p>
<div class="section level3">
<h3 id="sec:algo">Algorithms used<a class="anchor" aria-label="anchor" href="#sec:algo"></a>
</h3>
<p><strong>k-nearest neighbour (KNN)</strong> Function <em>knn</em> from
package <em><a href="https://bioconductor.org/packages/3.21/class" class="external-link">class</a></em>. For
each row of the test set, the <em>k</em> nearest (in Euclidean distance)
training set vectors are found, and the classification is decided by
majority vote over the <em>k</em> classes, with ties broken at random.
This is a simple algorithm that is often used as baseline classifier. If
there are ties for the <em>k</em>th nearest vector, all candidates are
included in the vote.</p>
<p><strong>Partial least square DA (PLS-DA)</strong> Function
<em>plsda</em> from package . Partial least square discriminant analysis
is used to fit a standard PLS model for classification.</p>
<p><strong>Support vector machine (SVM)</strong> A support vector
machine constructs a hyperplane (or set of hyperplanes for
multiple-class problem), which are then used for classification. The
best separation is defined as the hyperplane that has the largest
distance (the margin) to the nearest data points in any class, which
also reduces the classification generalisation error. To assure liner
separation of the classes, the data is transformed using a <em>kernel
function</em> into a high-dimensional space, permitting liner separation
of the classes.</p>
<p><em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>
makes use of the functions <em>svm</em> from package and <em>ksvm</em>
from .</p>
<p><strong>Artificial neural network (ANN)</strong> Function
<em>nnet</em> from package . Fits a single-hidden-layer neural network,
possibly with skip-layer connections.</p>
<p><strong>Naive Bayes (NB)</strong> Function <em>naiveBayes</em> from
package . Naive Bayes classifier that computes the conditional
a-posterior probabilities of a categorical class variable given
independent predictor variables using the Bayes rule. Assumes
independence of the predictor variables, and Gaussian distribution
(given the target class) of metric predictors.</p>
<p><strong>Random Forest (RF)</strong> Function <em>randomForest</em>
from package .</p>
<p><strong>Chi-square
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>)</strong>
Assignment based on squared differences between a labelled marker and a
new feature to be classified. Canonical protein correlation profile
method (PCP) uses squared differences between a labelled marker and new
features. In <span class="citation">(Andersen et al. 2003)</span>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msup><mi>χ</mi><mn>2</mn></msup><annotation encoding="application/x-tex">\chi^2</annotation></semantics></math>
is defined as ,
i.e. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>χ</mi><mn>2</mn></msup><mo>=</mo><mfrac><mrow><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><mi>n</mi></mfrac></mrow><annotation encoding="application/x-tex">\chi^{2} =
\frac{\sum_{i=1}^{n} (x_i - m_i)^{2}}{n}</annotation></semantics></math>,
whereas <span class="citation">(Wiese et al. 2007)</span> divide by the
value the squared value by the value of the reference feature in each
fraction,
i.e. <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>χ</mi><mn>2</mn></msup><mo>=</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><mfrac><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>−</mo><msub><mi>m</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup><msub><mi>m</mi><mi>i</mi></msub></mfrac></mrow><annotation encoding="application/x-tex">\chi^{2} = \sum_{i=1}^{n}\frac{(x_i -
m_i)^{2}}{m_i}</annotation></semantics></math>, where
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>x</mi><mi>i</mi></msub><annotation encoding="application/x-tex">x_i</annotation></semantics></math>
is normalised intensity of feature <em>x</em> in fraction <em>i</em>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>m</mi><mi>i</mi></msub><annotation encoding="application/x-tex">m_i</annotation></semantics></math>
is the normalised intensity of marker <em>m</em> in fraction <em>i</em>
and <em>n</em> is the number of fractions available. We will use the
former definition.</p>
<p><strong>PerTurbo </strong> From <span class="citation">(Courty,
Burger, and Laurent 2011)</span>: PerTurbo, an original, non-parametric
and efficient classification method is presented here. In our framework,
the manifold of each class is characterised by its Laplace-Beltrami
operator, which is evaluated with classical methods involving the graph
Laplacian. The classification criterion is established thanks to a
measure of the magnitude of the spectrum perturbation of this operator.
The first experiments show good performances against classical
algorithms of the state-of-the-art. Moreover, from this measure is
derived an efficient policy to design sampling queries in a context of
active learning. Performances collected over toy examples and real world
datasets assess the qualities of this strategy.</p>
<p>The PerTurbo implementation comes from the <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>
packages.</p>
</div>
<div class="section level3">
<h3 id="estimating-algorithm-parameters">Estimating algorithm parameters<a class="anchor" aria-label="anchor" href="#estimating-algorithm-parameters"></a>
</h3>
<p>It is essential when applying any of the above classification
algorithms, to wisely set the algorithm parameters, as these can have an
important effect on the classification. Such parameters are for example
the width <em>sigma</em> of the Radial Basis Function (Gaussian kernel)
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>e</mi><mi>x</mi><mi>p</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>−</mi><mi>σ</mi><mo stretchy="false" form="postfix">∥</mo><mi>x</mi><mo>−</mo><mi>x</mi><mi>′</mi><msup><mo stretchy="false" form="postfix">∥</mo><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">exp(-\sigma \| x - x' \|^2 )</annotation></semantics></math>
and the <em>cost</em> (slack) parameter (controlling the tolerance to
mis-classification) of our SVM classifier. The number of neighbours
<em>k</em> of the KNN classifier is equally important as will be
discussed in this sections.</p>
<p>The <a href="#fig:knnboundaries">next figure</a> illustrates the
effect of different choices of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
using organelle proteomics data from <span class="citation">(Dunkley et
al. 2006)</span> (<em>dunkley2006</em> from <em><a href="https://bioconductor.org/packages/3.21/pRolocdata" class="external-link">pRolocdata</a></em>).
As highlighted in the squared region, we can see that using a low
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
(<em>k = 1</em> on the left) will result in very specific classification
boundaries that precisely follow the contour or our marker set as
opposed to a higher number of neighbours (<em>k = 8</em> on the right).
While one could be tempted to believe that <em>optimised</em>
classification boundaries are preferable, it is essential to remember
that these boundaries are specific to the marker set used to construct
them, while there is absolutely no reason to expect these regions to
faithfully separate any new data points, in particular proteins that we
wish to classify to an organelle. In other words, the highly specific
<em>k = 1</em> classification boundaries are <em>over-fitted</em> for
the marker set or, in other words, lack generalisation to new instances.
We will demonstrate this using simulated data taken from <span class="citation">(James et al. 2013)</span> and show what detrimental
effect <em>over-fitting</em> has on new data.</p>
<div class="float" id="fig:knnboundaries">
<img src="Figures/knnboundaries.png" alt="Classification boundaries using k=1 or k=8 on the dunkley2006 data."><div class="figcaption">Classification boundaries using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math>
or
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">k=8</annotation></semantics></math>
on the <code>dunkley2006</code> data.</div>
</div>
<p>The <a href="#fig:ISL1">figure below</a> uses 2 <em>x</em> 100
simulated data points belonging to either of the orange or blue classes.
The genuine classes for all the points is known (solid lines) and the
KNN algorithm has been applied using <em>k = 1</em> (left) and <em>k =
100</em> (right) respectively (purple dashed lines). As in our organelle
proteomics examples, we observe that when k = 1, the decision boundaries
are overly flexible and identify patterns in the data that do not
reflect to correct boundaries (in such cases, the classifier is said to
have low bias but very high variance). When a large <em>k</em> is used,
the classifier becomes inflexible and produces approximate and nearly
linear separation boundaries (such a classifier is said to have low
variance but high bias). On this simulated data set, neither <em>k =
1</em> nor <em>k = 100</em> give good predictions and have test error
rates (i.e. the proportion of wrongly classified points) of 0.1695 and
0.1925, respectively.</p>
<div class="float" id="fig:ISL1">
<img src="Figures/ISL-2_16.png" alt="The KNN classifier using k = 1 (left, solid classification boundaries) and k = 100 (right, solid classification boundaries) compared the Bayes decision boundaries (see original material for details). Reproduced with permission from (James et al. 2013)."><div class="figcaption">The KNN classifier using
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k = 1</annotation></semantics></math>
(left, solid classification boundaries) and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>100</mn></mrow><annotation encoding="application/x-tex">k = 100</annotation></semantics></math>
(right, solid classification boundaries) compared the Bayes decision
boundaries (see original material for details). Reproduced with
permission from <span class="citation">(James et al. 2013)</span>.</div>
</div>
<p>To quantify the effect of flexibility and lack thereof in defining
the classification boundaries, <span class="citation">(James et al.
2013)</span> calculate the classification error rates using training
data (training error rate) and testing data (testing error rate). The
latter is completely new data that was not used to assess the model
error rate when defining algorithm parameters; one often says that the
model used for classification has not <em>seen</em> this data. If the
model performs well on new data, it is said to generalise well. This is
a quality that is required in most cases, and in particular in our
organelle proteomics experiments where the training data corresponds to
our marker sets. Figure @ref{fig:ISL2} plots the respective training and
testing error rates as a function of <em>1/k</em> which is a reflection
of the flexibility/complexity of our model; when <em>1/k = 1</em>,
i.e. <em>k = 1</em> (far right), we have a very flexible model with the
risk of over-fitting. Greater values of <em>k</em> (towards the left)
characterise less flexible models. As can be seen, high values of
<em>k</em> produce poor performance for both training and testing data.
However, while the training error steadily decreases when the model
complexity increases (smaller <em>k</em>), the testing error rate
displays a typical U-shape: at a value around <em>k = 10</em>, the
testing error rate reaches a minimum and then starts to increase due to
over-fitting to the training data and lack of generalisation of the
model.</p>
<div class="float" id="fig:ISL2">
<img src="Figures/ISL-2_17.png" alt="Effect of train and test error with respect to model complexity. The former decreases for lower values of k while the test error reaches a minimum around k = 10 before increasing again. Reproduced with permission from (James et al. 2013)."><div class="figcaption">Effect of train and test error with respect to
model complexity. The former decreases for lower values of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
while the test error reaches a minimum around
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">k = 10</annotation></semantics></math>
before increasing again. Reproduced with permission from <span class="citation">(James et al. 2013)</span>.</div>
</div>
<p>These results show that adequate optimisation of the model parameters
are essential to avoid either too flexible models (that do not
generalise well to new data) or models that do not describe the decision
boundaries adequately. Such parameter selection is achieved by cross
validation, where the initial marker proteins are separated into
training data used to build classification models and independent
testing data used to assess the model on new data.</p>
<p>We recommend the book <em>An Introduction to Statistical
Learning</em> (<a href="http://www-bcf.usc.edu/~gareth/ISL/" class="external-link uri">http://www-bcf.usc.edu/~gareth/ISL/</a>) by <span class="citation">(James et al. 2013)</span> for a more detailed
introduction of machine learning.</p>
</div>
<div class="section level3">
<h3 id="default-analysis-scheme">Default analysis scheme<a class="anchor" aria-label="anchor" href="#default-analysis-scheme"></a>
</h3>
<p>Below, we present a typical classification analysis using <em><a href="https://bioconductor.org/packages/3.21/pRoloc" class="external-link">pRoloc</a></em>.
The analysis typically consists of two steps. The first one is to
optimise the classifier parameters to be used for training and testing
(see above). A range of parameters are tested using the labelled data,
for which the labels are known. For each set of parameters, we hide the
labels of a subset of labelled data and use the other part to train a
model and apply in on the testing data with hidden labels. The
comparison of the estimated and expected labels enables to assess the
validity of the model and hence the adequacy if the parameters. Once
adequate parameters have been identified, they are used to infer a model
on the complete organelle marker set and used to infer the sub-cellular
location of the unlabelled examples.</p>
</div>
<div class="section level3">
<h3 class="unnumbered" id="parameter-optimisation">Parameter optimisation<a class="anchor" aria-label="anchor" href="#parameter-optimisation"></a>
</h3>
<p>Algorithmic performance is estimated using a stratified 20/80
partitioning. The 80% partitions are subjected to 5-fold
cross-validation in order to optimise free parameters via a grid search,
and these parameters are then applied to the remaining 20%. The
procedure is repeated <em>n = 100</em> <code>times</code> to sample
<em>n</em> accuracy metrics (see below) values using <em>n</em>,
possibly different, optimised parameters for evaluation.</p>
<p>Models accuracy is evaluated using the F1 score,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mspace width="0.222em"></mspace><mfrac><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>×</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>+</mo><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">F1 = 2 ~ \frac{precision \times recall}{precision + recall}</annotation></semantics></math>,
calculated as the harmonic mean of the precision
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>c</mi><mi>i</mi><mi>s</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>p</mi></mrow><mrow><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>p</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">precision =
\frac{tp}{tp+fp}</annotation></semantics></math>, a measure of
<em>exactness</em> – returned output is a relevant result) and recall
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi><mi>e</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi>l</mi><mo>=</mo><mfrac><mrow><mi>t</mi><mi>p</mi></mrow><mrow><mi>t</mi><mi>p</mi><mo>+</mo><mi>f</mi><mi>n</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">recall=\frac{tp}{tp+fn}</annotation></semantics></math>,
a measure of <em>completeness</em> – indicating how much was missed from
the output). What we are aiming for are high generalisation accuracy,
i.e high
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mn>1</mn></mrow><annotation encoding="application/x-tex">F1</annotation></semantics></math>,
indicating that the marker proteins in the test data set are
consistently correctly assigned by the algorithms.</p>
<p>The results of the optimisation procedure are stored in an
<em>GenRegRes</em> object that can be inspected, plotted and best
parameter pairs can be extracted.</p>
<p>For a given algorithm <code>alg</code>, the corresponding parameter
optimisation function is names <em>algOptimisation</em> or,
equivalently, <em>algOptimization</em>. See the table below for details.
A description of each of the respective model parameters is provided in
the optimisation function manuals, available through
<em>?algOptimisation</em>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">params</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/svmOptimisation.html">svmOptimisation</a></span><span class="op">(</span><span class="va">tan2009r1</span>, times <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                          xval <span class="op">=</span> <span class="fl">5</span>, verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">params</span></span></code></pre></div>
<pre><code><span><span class="co">## Object of class "GenRegRes"</span></span>
<span><span class="co">## Algorithm: svm </span></span>
<span><span class="co">## Hyper-parameters:</span></span>
<span><span class="co">##  cost: 0.0625 0.125 0.25 0.5 1 2 4 8 16</span></span>
<span><span class="co">##  sigma: 0.001 0.01 0.1 1 10 100</span></span>
<span><span class="co">## Design:</span></span>
<span><span class="co">##  Replication: 10 x 5-fold X-validation</span></span>
<span><span class="co">##  Partitioning: 0.2/0.8 (test/train)</span></span>
<span><span class="co">## Results</span></span>
<span><span class="co">##  macro F1:</span></span>
<span><span class="co">##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span></span>
<span><span class="co">##  0.7804  0.8085  0.8211  0.8412  0.8842  0.9385 </span></span>
<span><span class="co">##  best sigma: 0.1 1   </span></span>
<span><span class="co">##  best cost: 8 16 2 1   </span></span>
<span><span class="co">## Use getWarnings() to see warnings.</span></span></code></pre>
</div>
<div class="section level3">
<h3 class="unnumbered" id="classification">Classification<a class="anchor" aria-label="anchor" href="#classification"></a>
</h3>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tan2009r1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/svmClassification.html">svmClassification</a></span><span class="op">(</span><span class="va">tan2009r1</span>, <span class="va">params</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## [1] "markers"</span></span></code></pre>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tan2009r1</span></span></code></pre></div>
<pre><code><span><span class="co">## MSnSet (storageMode: lockedEnvironment)</span></span>
<span><span class="co">## assayData: 888 features, 4 samples </span></span>
<span><span class="co">##   element names: exprs </span></span>
<span><span class="co">## protocolData: none</span></span>
<span><span class="co">## phenoData</span></span>
<span><span class="co">##   sampleNames: X114 X115 X116 X117</span></span>
<span><span class="co">##   varLabels: Fractions</span></span>
<span><span class="co">##   varMetadata: labelDescription</span></span>
<span><span class="co">## featureData</span></span>
<span><span class="co">##   featureNames: P20353 P53501 ... P07909 (888 total)</span></span>
<span><span class="co">##   fvarLabels: FBgn Protein.ID ... svm.scores (18 total)</span></span>
<span><span class="co">##   fvarMetadata: labelDescription</span></span>
<span><span class="co">## experimentData: use 'experimentData(object)'</span></span>
<span><span class="co">##   pubMedIds: 19317464 </span></span>
<span><span class="co">## Annotation:  </span></span>
<span><span class="co">## - - - Processing information - - -</span></span>
<span><span class="co">## Added markers from  'mrk' marker vector. Thu Jul 16 22:53:44 2015 </span></span>
<span><span class="co">## Performed svm prediction (sigma=1 cost=2) Sat Nov 23 15:34:36 2024 </span></span>
<span><span class="co">##  MSnbase version: 1.17.12</span></span></code></pre>
</div>
<div class="section level3">
<h3 id="customising-model-parameters">Customising model parameters<a class="anchor" aria-label="anchor" href="#customising-model-parameters"></a>
</h3>
<p>Below we illustrate how to weight different classes according to the
number of labelled instances, where large sets are down weighted. This
strategy can help with imbalanced designs.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">w</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/BiocGenerics/man/table.html" class="external-link">table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Biobase/man/featureData.html" class="external-link">fData</a></span><span class="op">(</span><span class="fu"><a href="../reference/markerMSnSet.html">markerMSnSet</a></span><span class="op">(</span><span class="va">dunkley2006</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">markers</span><span class="op">)</span></span>
<span><span class="va">wpar</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/svmOptimisation.html">svmOptimisation</a></span><span class="op">(</span><span class="va">dunkley2006</span>, class.weights <span class="op">=</span> <span class="va">w</span><span class="op">)</span></span>
<span><span class="va">wres</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/svmClassification.html">svmClassification</a></span><span class="op">(</span><span class="va">dunkley2006</span>, <span class="va">wpar</span>, class.weights <span class="op">=</span> <span class="va">w</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<colgroup>
<col width="24%">
<col width="24%">
<col width="37%">
<col width="13%">
</colgroup>
<thead><tr class="header">
<th align="left">parameter optimisation</th>
<th align="left">classification</th>
<th align="left">algorithm</th>
<th align="left">package</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">knnOptimisation</td>
<td align="left">knnClassification</td>
<td align="left">nearest neighbour</td>
<td align="left">class</td>
</tr>
<tr class="even">
<td align="left">knntlOptimisation</td>
<td align="left">knntlClassification</td>
<td align="left">nearest neighbour transfer learning</td>
<td align="left">pRoloc</td>
</tr>
<tr class="odd">
<td align="left">ksvmOptimisation</td>
<td align="left">ksvmClassification</td>
<td align="left">support vector machine</td>
<td align="left">kernlab</td>
</tr>
<tr class="even">
<td align="left">nbOptimisation</td>
<td align="left">nbClassification</td>
<td align="left">naive bayes</td>
<td align="left">e1071</td>
</tr>
<tr class="odd">
<td align="left">nnetOptimisation</td>
<td align="left">nnetClassification</td>
<td align="left">neural networks</td>
<td align="left">nnet</td>
</tr>
<tr class="even">
<td align="left">perTurboOptimisation</td>
<td align="left">perTurboClassification</td>
<td align="left">PerTurbo</td>
<td align="left">pRoloc</td>
</tr>
<tr class="odd">
<td align="left">plsdaOptimisation</td>
<td align="left">plsdaClassification</td>
<td align="left">partial least square</td>
<td align="left">caret</td>
</tr>
<tr class="even">
<td align="left">rfOptimisation</td>
<td align="left">rfClassification</td>
<td align="left">random forest</td>
<td align="left">randomForest</td>
</tr>
<tr class="odd">
<td align="left">svmOptimisation</td>
<td align="left">svmClassification</td>
<td align="left">support vector machine</td>
<td align="left">e1071</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section level2">
<h2 id="comparison-of-different-classifiers">Comparison of different classifiers<a class="anchor" aria-label="anchor" href="#comparison-of-different-classifiers"></a>
</h2>
<p>Several supervised machine learning algorithms have already been
applied to organelle proteomics data classification: partial least
square discriminant analysis in <span class="citation">(Dunkley et al.
2006, Tan2009)</span>, support vector machines (SVMs) in <span class="citation">(Trotter et al. 2010)</span>, random forest in <span class="citation">(Ohta et al. 2010)</span>, neural networks in <span class="citation">(Tardif et al. 2012)</span>, naive Bayes <span class="citation">(Nikolovski et al. 2012)</span>. In our HUPO 2011
poster<a class="footnote-ref" tabindex="0" data-bs-toggle="popover" data-bs-content='&lt;p&gt;Gatto, Laurent; Breckels, Lisa M.; Trotter, Matthew
W.B.; Lilley, Kathryn S. (2011): &lt;code&gt;pRoloc&lt;/code&gt; - A unifying
bioinformatics framework for organelle proteomics. &lt;a href="https://doi.org/10.6084/m9.figshare.5042965.v1" class="external-link uri"&gt;https://doi.org/10.6084/m9.figshare.5042965.v1&lt;/a&gt;&lt;/p&gt;'><sup>1</sup></a>,
we show that different classification algorithms provide very similar
performance. We have extended this comparison on various datasets
distributed in the <em><a href="https://bioconductor.org/packages/3.21/pRolocdata" class="external-link">pRolocdata</a></em>
package. On figure @ref{fig:f1box}, we illustrate how different
algorithms reach very similar performances on most of our test
datasets.</p>
<div class="float" id="fig:f1box">
<img src="Figures/F1boxplots.png" alt="Comparison of classification performances of several contemporary classification algorithms on data from the pRolocdata package."><div class="figcaption">Comparison of classification performances of
several contemporary classification algorithms on data from the <em><a href="https://bioconductor.org/packages/3.21/pRolocdata" class="external-link">pRolocdata</a></em>
package.</div>
</div>
</div>
<div class="section level2">
<h2 id="sec:bayes">Bayesian generative models<a class="anchor" aria-label="anchor" href="#sec:bayes"></a>
</h2>
<p>We also offer generative models that, as opposed to the descriptive
classifier presented above, explicitly model the spatial proteomics
data. In <code>pRoloc</code>, we probose two models using T-augmented
Gaussian mixtures using repectively a Expectration-Maximisation approach
to <em>maximum a posteriori</em> estimation of the model parameters
(TAGM-MAP), and an MCMC approach (TAGM-MCMC) that enables a
proteome-wide uncertainty quantitation. These methods are described in
the <em>pRoloc-bayesian</em> vignette.</p>
<p>For a details description of the methods and their validation, please
refer to <span class="citation">(Crook et al. 2018)</span>:</p>
<blockquote>
<p>A Bayesian Mixture Modelling Approach For Spatial Proteomics Oliver M
Crook, Claire M Mulvey, Paul D. W. Kirk, Kathryn S Lilley, Laurent Gatto
bioRxiv 282269; doi: <a href="https://doi.org/10.1101/282269" class="external-link uri">https://doi.org/10.1101/282269</a></p>
</blockquote>
</div>
<div class="section level2">
<h2 id="sec:ssml">Semi-supervised machine learning<a class="anchor" aria-label="anchor" href="#sec:ssml"></a>
</h2>
<p>The <em>phenoDisco</em> algorithm is a semi-supervised novelty
detection method by <span class="citation">(Lisa M. Breckels et al.
2013)</span> (<a href="#fig:pd">figure below</a>). It uses the labelled
(i.e. markers, noted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>D</mi><mi>L</mi></msub><annotation encoding="application/x-tex">D_L</annotation></semantics></math>)
and unlabelled (i.e. proteins of unknown localisation, noted
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>D</mi><mi>U</mi></msub><annotation encoding="application/x-tex">D_U</annotation></semantics></math>)
sets of the input data. The algorithm is repeated
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
times (the <code>times</code> argument in the <em>phenoDisco</em>
function). At each iteration, each organelle class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>D</mi><mi>L</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">D_{L}^{i}</annotation></semantics></math>
and the unlabelled complement are clustered using Gaussian mixture
modelling. While unlabelled members that systematically cluster with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>D</mi><mi>L</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">D_{L}^{i}</annotation></semantics></math>
and pass outlier detection are labelled as new putative members of class
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
any example of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>D</mi><mi>U</mi></msub><annotation encoding="application/x-tex">D_U</annotation></semantics></math>
which are not merged with any any of the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msubsup><mi>D</mi><mi>L</mi><mi>i</mi></msubsup><annotation encoding="application/x-tex">D_{L}^{i}</annotation></semantics></math>
and are consistently clustered together throughout the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math>
iterations are considered members of a new phenotype.</p>
<div class="float" id="fig:pd">
<img src="Figures/phenodisco.png" alt="The PhenoDisco iterative algorithm."><div class="figcaption">The PhenoDisco iterative algorithm.</div>
</div>
</div>
<div class="section level2">
<h2 id="sec:tl">Transfer learning<a class="anchor" aria-label="anchor" href="#sec:tl"></a>
</h2>
<p>When multiple sources of data are available, it is often beneficial
to take all or several into account with the aim of increasing the
information to tackle a problem of interest. While it is at times
possible to combine these different sources of data, this can lead to
substantially harm to performance of the analysis when the different
data sources are of variable signal-to-noise ratio or the data are drawn
from different domains and recorded by different encoding (quantitative
and binary, for example). If we defined the following two data
source</p>
<ol style="list-style-type: decimal">
<li>
<em>primary</em> data, of high signal-to-noise ratio, but general
available in limited amounts;</li>
<li>
<em>auxiliary</em> data, of limited signal-to-noise, and available
in large amounts;</li>
</ol>
<p>then, a <em>transfer learning</em> algorithm will efficiently
support/complement the primary target domain with auxiliary data
features without compromising the integrity of our primary data.</p>
<p>We have developed a transfer learning framework <span class="citation">(L. M. Breckels et al. 2016)</span> and applied to the
analysis of spatial proteomics data, as described in the
<code>pRoloc-transfer-learning</code> vignette.</p>
</div>
<div class="section level2">
<h2 id="session-information">Session information<a class="anchor" aria-label="anchor" href="#session-information"></a>
</h2>
<p>All software and respective versions used to produce this document
are listed below.</p>
<pre><code><span><span class="co">## R Under development (unstable) (2024-11-20 r87352)</span></span>
<span><span class="co">## Platform: x86_64-pc-linux-gnu</span></span>
<span><span class="co">## Running under: Ubuntu 24.04.1 LTS</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## Matrix products: default</span></span>
<span><span class="co">## BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 </span></span>
<span><span class="co">## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## locale:</span></span>
<span><span class="co">##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              </span></span>
<span><span class="co">##  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    </span></span>
<span><span class="co">##  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   </span></span>
<span><span class="co">##  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 </span></span>
<span><span class="co">##  [9] LC_ADDRESS=C               LC_TELEPHONE=C            </span></span>
<span><span class="co">## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## time zone: UTC</span></span>
<span><span class="co">## tzcode source: system (glibc)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">## attached base packages:</span></span>
<span><span class="co">## [1] stats4    stats     graphics  grDevices utils     datasets  methods  </span></span>
<span><span class="co">## [8] base     </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## other attached packages:</span></span>
<span><span class="co">##  [1] pRolocdata_1.45.0    pRoloc_1.45.3        BiocParallel_1.41.0 </span></span>
<span><span class="co">##  [4] MLInterfaces_1.87.0  cluster_2.1.6        annotate_1.85.0     </span></span>
<span><span class="co">##  [7] XML_3.99-0.17        AnnotationDbi_1.69.0 IRanges_2.41.1      </span></span>
<span><span class="co">## [10] MSnbase_2.33.2       ProtGenerics_1.39.0  S4Vectors_0.45.2    </span></span>
<span><span class="co">## [13] mzR_2.41.1           Rcpp_1.0.13-1        Biobase_2.67.0      </span></span>
<span><span class="co">## [16] BiocGenerics_0.53.3  generics_0.1.3       knitr_1.49          </span></span>
<span><span class="co">## [19] BiocStyle_2.35.0    </span></span>
<span><span class="co">## </span></span>
<span><span class="co">## loaded via a namespace (and not attached):</span></span>
<span><span class="co">##   [1] splines_4.5.0               filelock_1.0.3             </span></span>
<span><span class="co">##   [3] tibble_3.2.1                hardhat_1.4.0              </span></span>
<span><span class="co">##   [5] preprocessCore_1.69.0       pROC_1.18.5                </span></span>
<span><span class="co">##   [7] rpart_4.1.23                lifecycle_1.0.4            </span></span>
<span><span class="co">##   [9] httr2_1.0.6                 doParallel_1.0.17          </span></span>
<span><span class="co">##  [11] globals_0.16.3              lattice_0.22-6             </span></span>
<span><span class="co">##  [13] MASS_7.3-61                 MultiAssayExperiment_1.33.1</span></span>
<span><span class="co">##  [15] dendextend_1.19.0           magrittr_2.0.3             </span></span>
<span><span class="co">##  [17] limma_3.63.2                plotly_4.10.4              </span></span>
<span><span class="co">##  [19] sass_0.4.9                  rmarkdown_2.29             </span></span>
<span><span class="co">##  [21] jquerylib_0.1.4             yaml_2.3.10                </span></span>
<span><span class="co">##  [23] MsCoreUtils_1.19.0          DBI_1.2.3                  </span></span>
<span><span class="co">##  [25] RColorBrewer_1.1-3          lubridate_1.9.3            </span></span>
<span><span class="co">##  [27] abind_1.4-8                 zlibbioc_1.53.0            </span></span>
<span><span class="co">##  [29] GenomicRanges_1.59.1        purrr_1.0.2                </span></span>
<span><span class="co">##  [31] mixtools_2.0.0              AnnotationFilter_1.31.0    </span></span>
<span><span class="co">##  [33] nnet_7.3-19                 rappdirs_0.3.3             </span></span>
<span><span class="co">##  [35] ipred_0.9-15                lava_1.8.0                 </span></span>
<span><span class="co">##  [37] GenomeInfoDbData_1.2.13     listenv_0.9.1              </span></span>
<span><span class="co">##  [39] gdata_3.0.1                 parallelly_1.39.0          </span></span>
<span><span class="co">##  [41] pkgdown_2.1.1.9000          ncdf4_1.23                 </span></span>
<span><span class="co">##  [43] codetools_0.2-20            DelayedArray_0.33.2        </span></span>
<span><span class="co">##  [45] xml2_1.3.6                  tidyselect_1.2.1           </span></span>
<span><span class="co">##  [47] UCSC.utils_1.3.0            viridis_0.6.5              </span></span>
<span><span class="co">##  [49] matrixStats_1.4.1           BiocFileCache_2.15.0       </span></span>
<span><span class="co">##  [51] jsonlite_1.8.9              caret_6.0-94               </span></span>
<span><span class="co">##  [53] e1071_1.7-16                survival_3.7-0             </span></span>
<span><span class="co">##  [55] iterators_1.0.14            systemfonts_1.1.0          </span></span>
<span><span class="co">##  [57] foreach_1.5.2               segmented_2.1-3            </span></span>
<span><span class="co">##  [59] tools_4.5.0                 progress_1.2.3             </span></span>
<span><span class="co">##  [61] ragg_1.3.3                  glue_1.8.0                 </span></span>
<span><span class="co">##  [63] prodlim_2024.06.25          gridExtra_2.3              </span></span>
<span><span class="co">##  [65] SparseArray_1.7.2           xfun_0.49                  </span></span>
<span><span class="co">##  [67] MatrixGenerics_1.19.0       GenomeInfoDb_1.43.1        </span></span>
<span><span class="co">##  [69] dplyr_1.1.4                 withr_3.0.2                </span></span>
<span><span class="co">##  [71] BiocManager_1.30.25         fastmap_1.2.0              </span></span>
<span><span class="co">##  [73] fansi_1.0.6                 digest_0.6.37              </span></span>
<span><span class="co">##  [75] timechange_0.3.0            R6_2.5.1                   </span></span>
<span><span class="co">##  [77] textshaping_0.4.0           colorspace_2.1-1           </span></span>
<span><span class="co">##  [79] gtools_3.9.5                lpSolve_5.6.22             </span></span>
<span><span class="co">##  [81] biomaRt_2.63.0              RSQLite_2.3.8              </span></span>
<span><span class="co">##  [83] utf8_1.2.4                  tidyr_1.3.1                </span></span>
<span><span class="co">##  [85] hexbin_1.28.5               data.table_1.16.2          </span></span>
<span><span class="co">##  [87] recipes_1.1.0               FNN_1.1.4.1                </span></span>
<span><span class="co">##  [89] class_7.3-22                prettyunits_1.2.0          </span></span>
<span><span class="co">##  [91] PSMatch_1.11.0              httr_1.4.7                 </span></span>
<span><span class="co">##  [93] htmlwidgets_1.6.4           S4Arrays_1.7.1             </span></span>
<span><span class="co">##  [95] ModelMetrics_1.2.2.2        pkgconfig_2.0.3            </span></span>
<span><span class="co">##  [97] gtable_0.3.6                timeDate_4041.110          </span></span>
<span><span class="co">##  [99] blob_1.2.4                  impute_1.81.0              </span></span>
<span><span class="co">## [101] XVector_0.47.0              htmltools_0.5.8.1          </span></span>
<span><span class="co">## [103] bookdown_0.41               MALDIquant_1.22.3          </span></span>
<span><span class="co">## [105] clue_0.3-66                 scales_1.3.0               </span></span>
<span><span class="co">## [107] png_0.1-8                   gower_1.0.1                </span></span>
<span><span class="co">## [109] reshape2_1.4.4              coda_0.19-4.1              </span></span>
<span><span class="co">## [111] nlme_3.1-166                curl_6.0.1                 </span></span>
<span><span class="co">## [113] proxy_0.4-27                cachem_1.1.0               </span></span>
<span><span class="co">## [115] stringr_1.5.1               parallel_4.5.0             </span></span>
<span><span class="co">## [117] mzID_1.45.0                 vsn_3.75.0                 </span></span>
<span><span class="co">## [119] desc_1.4.3                  pillar_1.9.0               </span></span>
<span><span class="co">## [121] grid_4.5.0                  vctrs_0.6.5                </span></span>
<span><span class="co">## [123] pcaMethods_1.99.0           randomForest_4.7-1.2       </span></span>
<span><span class="co">## [125] dbplyr_2.5.0                xtable_1.8-4               </span></span>
<span><span class="co">## [127] evaluate_1.0.1              mvtnorm_1.3-2              </span></span>
<span><span class="co">## [129] cli_3.6.3                   compiler_4.5.0             </span></span>
<span><span class="co">## [131] rlang_1.1.4                 crayon_1.5.3               </span></span>
<span><span class="co">## [133] future.apply_1.11.3         LaplacesDemon_16.1.6       </span></span>
<span><span class="co">## [135] mclust_6.1.1                QFeatures_1.17.0           </span></span>
<span><span class="co">## [137] affy_1.85.0                 plyr_1.8.9                 </span></span>
<span><span class="co">## [139] fs_1.6.5                    stringi_1.8.4              </span></span>
<span><span class="co">## [141] viridisLite_0.4.2           munsell_0.5.1              </span></span>
<span><span class="co">## [143] Biostrings_2.75.1           lazyeval_0.2.2             </span></span>
<span><span class="co">## [145] Matrix_1.7-1                hms_1.1.3                  </span></span>
<span><span class="co">## [147] bit64_4.5.2                 future_1.34.0              </span></span>
<span><span class="co">## [149] ggplot2_3.5.1               KEGGREST_1.47.0            </span></span>
<span><span class="co">## [151] statmod_1.5.0               SummarizedExperiment_1.37.0</span></span>
<span><span class="co">## [153] kernlab_0.9-33              igraph_2.1.1               </span></span>
<span><span class="co">## [155] memoise_2.0.1               affyio_1.77.0              </span></span>
<span><span class="co">## [157] bslib_0.8.0                 sampling_2.10              </span></span>
<span><span class="co">## [159] bit_4.5.0</span></span></code></pre>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Andersen2003" class="csl-entry">
Andersen, Jens S., Christopher J. Wilkinson, Thibault Mayor, Peter
Mortensen, Erich A. Nigg, and Matthias Mann. 2003. <span>“Proteomic
Characterization of the Human Centrosome by Protein Correlation
Profiling.”</span> <em>Nature</em> 426 (6966): 570–74. <a href="https://doi.org/10.1038/nature02166" class="external-link">https://doi.org/10.1038/nature02166</a>.
</div>
<div id="ref-Breckels:2016" class="csl-entry">
Breckels, L M, S B Holden, D Wojnar, C M Mulvey, A Christoforou, A
Groen, M W Trotter, O Kohlbacher, K S Lilley, and L Gatto. 2016.
<span>“Learning from Heterogeneous Data Sources: An Application in
Spatial Proteomics.”</span> <em>PLoS Comput Biol</em> 12 (5): e1004920.
<a href="https://doi.org/10.1371/journal.pcbi.1004920" class="external-link">https://doi.org/10.1371/journal.pcbi.1004920</a>.
</div>
<div id="ref-Breckels2013" class="csl-entry">
Breckels, Lisa M, Laurent Gatto, Andy Christoforou, Arnoud J Groen,
Kathryn S Lilley, and Matthew W B Trotter. 2013. <span>“The Effect of
Organelle Discovery Upon Sub-Cellular Protein Localisation.”</span>
<em>J Proteomics</em>, March. <a href="https://doi.org/10.1016/j.jprot.2013.02.019" class="external-link">https://doi.org/10.1016/j.jprot.2013.02.019</a>.
</div>
<div id="ref-MLInterfaces" class="csl-entry">
Carey, Vince, Robert Gentleman, Jess Mar, and contributions from Jason
Vertrees, and Laurent Gatto. n.d. <em><span>MLInterfaces</span>: Uniform
Interfaces to r Machine Learning Procedures for Data in Bioconductor
Containers</em>.
</div>
<div id="ref-perturbo" class="csl-entry">
Courty, Nicolas, Thomas Burger, and Johann Laurent. 2011.
<span>“PerTurbo: A New Classification Algorithm Based on the Spectrum
Perturbations of the Laplace-Beltrami Operator.”</span> In <em>In the
Proceedings of ECML/PKDD (1)</em>, edited by Dimitrios Gunopulos, Thomas
Hofmann, Donato Malerba, and Michalis Vazirgiannis, 6911:359–74. Lecture
Notes in Computer Science. Springer.
</div>
<div id="ref-Crook:2018" class="csl-entry">
Crook, Oliver M, Claire M Mulvey, Paul D. W. Kirk, Kathryn S Lilley, and
Laurent Gatto. 2018. <span>“A Bayesian Mixture Modelling Approach for
Spatial Proteomics.”</span> <em>bioRxiv</em>. <a href="https://doi.org/10.1101/282269" class="external-link">https://doi.org/10.1101/282269</a>.
</div>
<div id="ref-Dunkley2006" class="csl-entry">
Dunkley, Tom P. J., Svenja Hester, Ian P. Shadforth, John Runions, Thilo
Weimar, Sally L. Hanton, Julian L. Griffin, et al. 2006. <span>“Mapping
the Arabidopsis Organelle Proteome.”</span> <em>Proc Natl Acad Sci
USA</em> 103 (17): 6518–23. <a href="https://doi.org/10.1073/pnas.0506958103" class="external-link">https://doi.org/10.1073/pnas.0506958103</a>.
</div>
<div id="ref-ISLwR" class="csl-entry">
James, G., D. Witten, T. Hastie, and R. Tibshirani. 2013. <em>An
Introduction to Statistical Learning: With Applications in r</em>.
Springer Texts in Statistics. Springer.
</div>
<div id="ref-Nikolovski2012" class="csl-entry">
Nikolovski, N, D Rubtsov, M P Segura, G P Miles, T J Stevens, T P
Dunkley, S Munro, K S Lilley, and P Dupree. 2012. <span>“Putative
Glycosyltransferases and Other Plant Golgi Apparatus Proteins Are
Revealed by <span>LOPIT</span> Proteomics.”</span> <em>Plant
Physiol</em> 160 (2): 1037–51. <a href="https://doi.org/10.1104/pp.112.204263" class="external-link">https://doi.org/10.1104/pp.112.204263</a>.
</div>
<div id="ref-Ohta2010" class="csl-entry">
Ohta, S, J C Bukowski-Wills, L Sanchez-Pulido, Fde L Alves, L Wood, Z A
Chen, M Platani, et al. 2010. <span>“The Protein Composition of Mitotic
Chromosomes Determined Using Multiclassifier Combinatorial
Proteomics.”</span> <em>Cell</em> 142 (5): 810–21. <a href="https://doi.org/10.1016/j.cell.2010.07.047" class="external-link">https://doi.org/10.1016/j.cell.2010.07.047</a>.
</div>
<div id="ref-Tardif2012" class="csl-entry">
Tardif, M, A Atteia, M Specht, G Cogne, N Rolland, S Brugière, M
Hippler, et al. 2012. <span>“PredAlgo: A New Subcellular Localization
Prediction Tool Dedicated to Green Algae.”</span> <em>Mol Biol Evol</em>
29 (12): 3625–39. <a href="https://doi.org/10.1093/molbev/mss178" class="external-link">https://doi.org/10.1093/molbev/mss178</a>.
</div>
<div id="ref-Trotter2010" class="csl-entry">
Trotter, Matthew W. B., Pawel G. Sadowski, Tom P. J. Dunkley, Arnoud J.
Groen, and Kathryn S. Lilley. 2010. <span>“Improved Sub-Cellular
Resolution via Simultaneous Analysis of Organelle Proteomics Data Across
Varied Experimental Conditions.”</span> <em>PROTEOMICS</em> 10 (23):
4213–19. <a href="https://doi.org/10.1002/pmic.201000359" class="external-link">https://doi.org/10.1002/pmic.201000359</a>.
</div>
<div id="ref-Wiese2007" class="csl-entry">
Wiese, Sebastian, Thomas Gronemeyer, Rob Ofman, Markus Kunze, Cláudia P.
Grou, José A. Almeida, Martin Eisenacher, et al. 2007. <span>“Proteomics
Characterization of Mouse Kidney Peroxisomes by Tandem Mass Spectrometry
and Protein Correlation Profiling.”</span> <em>Mol Cell Proteomics</em>
6 (12): 2045–57. <a href="https://doi.org/10.1074/mcp.M700169-MCP200" class="external-link">https://doi.org/10.1074/mcp.M700169-MCP200</a>.
</div>
</div>
</div>

  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Laurent Gatto, Lisa Breckels, Oliver Crook.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.9000.</p>
</div>

    </footer>
</div>





  </body>
</html>
